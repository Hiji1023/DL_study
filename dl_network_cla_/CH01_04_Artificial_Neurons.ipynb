{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CH01_04. [구현강의]Artificial_Neurons.ipynb. [구현강의]Artificial_Neurons",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hiji1023/dl_network_cla_/blob/main/CH01_04_Artificial_Neurons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1-3:Activation Functions**#"
      ],
      "metadata": {
        "id": "cZYFspgmy_vr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Code1-3-1:Activation Layers**##"
      ],
      "metadata": {
        "id": "-gc6u1QxzVCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# activation fucn만 만드는 법\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import exp, maximum\n",
        "from tensorflow.keras.layers import Activation\n",
        "\n",
        "x = tf.random.normal(shape=(1,5))  #input setting \n",
        "\n",
        "# imp. activation function\n",
        "\n",
        "sigmoid = Activation('sigmoid')\n",
        "tanh = Activation('tanh')\n",
        "relu = Activation('relu')\n",
        "\n",
        "# forward propagation(Tensorflow)\n",
        "y_sigmoid_tf = sigmoid(x)\n",
        "y_tanh_tf = tanh(x)\n",
        "y_relu_tf = relu(x)\n",
        "\n",
        "# forward propagation(manual)     ,  실제 연산\n",
        "\n",
        "y_sigmoid_man  = 1 / (1 + exp(-x))\n",
        "y_tanh_man = (exp(x) - exp(-x)) / (exp(x) + exp(-x))\n",
        "y_relu_man = maximum(0,x)\n",
        "\n",
        "print(\"x : {}\\n{}\".format(x.shape, x.numpy()))\n",
        "print(\"Sigmoid(Tensorflow): {}\\n{}\".format(y_sigmoid_tf.shape, y_sigmoid_tf.numpy()))\n",
        "print(\"Sigmoid(manual): {}\\n{}\".format(y_sigmoid_man.shape, y_sigmoid_man.numpy()))\n",
        "\n",
        "print(\"Tanh(Tensorflow): {}\\n{}\".format(y_tanh_tf.shape, y_tanh_tf.numpy()))\n",
        "print(\"Tanh(manual): {}\\n{}\".format(y_tanh_man.shape, y_tanh_man.numpy()))\n",
        "\n",
        "print(\"ReLU(Tensorflow): {}\\n{}\".format(y_relu_tf.shape, y_relu_tf.numpy()))\n",
        "print(\"ReLU(manual): {}\\n{}\".format(y_relu_man.shape, y_relu_man.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWvQb0oFzUFQ",
        "outputId": "6e38fe10-011e-45c8-b530-50f7299ccf1b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x : (1, 5)\n",
            "[[ 1.807891    1.2539947  -0.93710077 -0.13290061 -0.48402297]]\n",
            "Sigmoid(Tensorflow): (1, 5)\n",
            "[[0.8591068  0.7779906  0.28148636 0.46682367 0.3813026 ]]\n",
            "Sigmoid(manual): (1, 5)\n",
            "[[0.8591068  0.7779906  0.28148636 0.46682364 0.38130262]]\n",
            "Tanh(Tensorflow): (1, 5)\n",
            "[[ 0.9476171   0.84940004 -0.7338874  -0.13212363 -0.4494597 ]]\n",
            "Tanh(manual): (1, 5)\n",
            "[[ 0.9476172   0.84940004 -0.7338874  -0.13212363 -0.4494597 ]]\n",
            "ReLU(Tensorflow): (1, 5)\n",
            "[[1.807891  1.2539947 0.        0.        0.       ]]\n",
            "ReLU(manual): (1, 5)\n",
            "[[1.807891  1.2539947 0.        0.        0.       ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Code1-3-2:Activation in Dense Layer**##"
      ],
      "metadata": {
        "id": "WIhXTzV5zTA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dense Layer안에 activation function 구현하기\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.math import exp, maximum\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "x = tf.random.normal(shape=(1,5))  #input setting \n",
        "\n",
        "# imp. artificial neurons\n",
        "dense_sigmoid = Dense(units=1, activation='sigmoid')  # affine + activation\n",
        "dense_tanh = Dense(units=1, activation='tanh')\n",
        "dense_relu = Dense(units=1, activation='relu')\n",
        "\n",
        "# forward propagation(Tensorflow)\n",
        "y_sigmoid = dense_sigmoid(x)\n",
        "y_tanh = dense_tanh(x)\n",
        "y_relu = dense_relu(x)\n",
        "\n",
        "# print resluts\n",
        "print(\"AN with Sigmoid: {}\\n{}\".format(y_sigmoid.shape, y_sigmoid.numpy()))\n",
        "print(\"AN with Tanh: {}\\n{}\".format(y_tanh.shape, y_tanh.numpy()))\n",
        "print(\"AN with ReLU: {}\\n{}\".format(y_relu.shape, y_relu.numpy()))\n",
        "\n",
        "# forward propagation(manual)\n",
        "print('\\n====\\n')\n",
        "\n",
        "W_sigmoid, B_sigmoid = dense_sigmoid.get_weights()\n",
        "z = tf.linalg.matmul(x,W_sigmoid) + B_sigmoid\n",
        "a_sigmoid  = 1 / (1 + exp(-z))\n",
        "print(\"Activation Sigmoid value(Tensorflow): {}\\n{}\".format(y_sigmoid.shape, y_sigmoid.numpy()))\n",
        "print(\"Activation Sigmoid value(manual): {}\\n{}\".format(a_sigmoid.shape, a_sigmoid.numpy()))\n",
        "\n",
        "W_tanh, B_tanh = dense_tanh.get_weights()\n",
        "z_tanh = tf.linalg.matmul(x,W_tanh) + B_tanh\n",
        "a_tanh  = (exp(z_tanh) - exp(-z_tanh)) / (exp(z_tanh) + exp(-z_tanh))\n",
        "print(\"Activation Tanh value(Tensorflow): {}\\n{}\".format(y_tanh.shape, y_tanh.numpy()))\n",
        "print(\"Activation Tanh value(manual): {}\\n{}\".format(a_tanh.shape, a_tanh.numpy()))\n",
        "\n",
        "W_relu, B_relu = dense_relu.get_weights()\n",
        "z_relu = tf.linalg.matmul(x,W_relu) + B_relu\n",
        "a_relu  = maximum(0,z_relu)\n",
        "print(\"Activation ReLU value(Tensorflow): {}\\n{}\".format(y_relu.shape, y_relu.numpy()))\n",
        "print(\"Activation ReLU value(manual): {}\\n{}\".format(a_relu.shape, a_relu.numpy()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVAFJ3HPzVZc",
        "outputId": "c58aa1f8-5e48-4e75-cb7c-3b4fe7ef82e2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AN with Sigmoid: (1, 1)\n",
            "[[0.48862118]]\n",
            "AN with Tanh: (1, 1)\n",
            "[[-0.06860781]]\n",
            "AN with ReLU: (1, 1)\n",
            "[[0.]]\n",
            "\n",
            "====\n",
            "\n",
            "Activation Sigmoid value(Tensorflow): (1, 1)\n",
            "[[0.48862118]]\n",
            "Activation Sigmoid value(manual): (1, 1)\n",
            "[[0.48862115]]\n",
            "Activation Tanh value(Tensorflow): (1, 1)\n",
            "[[-0.06860781]]\n",
            "Activation Tanh value(manual): (1, 1)\n",
            "[[-0.0686078]]\n",
            "Activation ReLU value(Tensorflow): (1, 1)\n",
            "[[0.]]\n",
            "Activation ReLU value(manual): (1, 1)\n",
            "[[0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1-4:Artificial Neurons**#"
      ],
      "metadata": {
        "id": "dyPGZAxBzqen"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Code1-4-1: Artificial Neurons**##"
      ],
      "metadata": {
        "id": "ISaZ2mZiz3eY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.math import exp, maximum\n",
        "\n",
        "#activation = 'sigmoid'\n",
        "#activation = 'tanh'\n",
        "activation = 'relu'\n",
        "\n",
        "#input setting\n",
        "x = tf.random.uniform(shape=(1,10))\n",
        "\n",
        "dense = Dense(units=1, activation=activation)  #imp. an affine + activation\n",
        "\n",
        "y_tf = dense(x)\n",
        "W, B = dense.get_weights()\n",
        "\n",
        "#calculate activation value manually\n",
        "y_man = tf.linalg.matmul(x,W) + B\n",
        "if activation == 'sigmoid' :\n",
        "  y_man = 1 / (1 + exp(-y_man))\n",
        "elif activation == 'tanh' :\n",
        "  y_man = (exp(y_man) - exp(-y_man)) / (exp(y_man) + exp(-y_man))\n",
        "elif activation == 'relu' :\n",
        "  y_man = maximum(0,y_man)\n",
        "\n",
        "print(\"Activation: \", activation)\n",
        "print(\"y_tf: {}\\n{}\\n\".format(y_tf.shape, y_tf.numpy()))\n",
        "print(\"y_man: {}\\n{}\\n\".format(y_man.shape, y_man.numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37EUgcFkz4yE",
        "outputId": "746602e5-2a73-4031-f23e-b92acb5306e5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation:  relu\n",
            "y_tf: (1, 1)\n",
            "[[0.48963225]]\n",
            "\n",
            "y_man: (1, 1)\n",
            "[[0.48963225]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1-5:MiniBatches**#"
      ],
      "metadata": {
        "id": "iLK-cCYGz47V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Code1-5-1: Shapes of Dense Layers**##"
      ],
      "metadata": {
        "id": "5SHBH-cxMuKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# set input params\n",
        "N, n_feature = 8, 10\n",
        "# generate minibatch\n",
        "x = tf.random.normal(shape=(N, n_feature))  # matrix형태, 8행10열\n",
        "\n",
        "# imp. an AN\n",
        "dense = Dense(units=1,activation='relu')\n",
        "#forward propagation\n",
        "y = dense(x)\n",
        "\n",
        "# get weight/bias\n",
        "W, B = dense.get_weights()\n",
        "\n",
        "#print results\n",
        "print(\"Shape of x: {}\", x.shape)\n",
        "print(\"Shape of W: {}\", W.shape)\n",
        "print(\"Shape of B: {}\", B.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20mh6yDzz5NW",
        "outputId": "3bba8817-1e44-49f6-9eee-2132a9ac6077"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x: {} (8, 10)\n",
            "Shape of W: {} (10, 1)\n",
            "Shape of B: {} (1,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Code1-5-2: Output Calculations**##"
      ],
      "metadata": {
        "id": "ziMO4TK2Mu82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# set input params\n",
        "N, n_feature = 8, 10\n",
        "# generate minibatch\n",
        "x = tf.random.normal(shape=(N, n_feature))  # matrix형태, 8행10열\n",
        "\n",
        "# imp. an AN\n",
        "dense = Dense(units=1,activation='sigmoid')\n",
        "#forward propagation(Tensorflow)\n",
        "y_tf = dense(x)\n",
        "\n",
        "W, B = dense.get_weights()\n",
        "\n",
        "#forward propagation(Tensorflow)\n",
        "y_man = tf.linalg.matmul(x,W) + B\n",
        "y_man = 1 / (1 + tf.math.exp(-y_man))\n",
        "# print results\n",
        "print(\"Output(Tensorflow): \\n\", y_tf.numpy())\n",
        "print(\"Output(manual): \\n\", y_man.numpy())\n",
        "#print(tf.math.equal(y_tf, y_man))  # floating point가 잘려 나와 항상 True가 아니다\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EonDzVZSMvE1",
        "outputId": "ee104a54-1b6d-4663-f5d4-f10b3588fd55"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output(Tensorflow): \n",
            " [[0.48920912]\n",
            " [0.57421196]\n",
            " [0.47956005]\n",
            " [0.5983009 ]\n",
            " [0.5136241 ]\n",
            " [0.35580188]\n",
            " [0.7624293 ]\n",
            " [0.80499876]]\n",
            "Output(manual): \n",
            " [[0.48920915]\n",
            " [0.574212  ]\n",
            " [0.47956005]\n",
            " [0.5983009 ]\n",
            " [0.5136241 ]\n",
            " [0.35580185]\n",
            " [0.76242924]\n",
            " [0.80499876]]\n"
          ]
        }
      ]
    }
  ]
}