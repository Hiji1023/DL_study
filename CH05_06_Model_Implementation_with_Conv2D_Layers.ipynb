{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CH05_06_Model_Implementation_with_Conv2D_Layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hiji1023/dl_network_cla_/blob/main/CH05_06_Model_Implementation_with_Conv2D_Layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**5-4: Models with Conv Layers**#"
      ],
      "metadata": {
        "id": "e_5np3TcRxOJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**5-4-1: Models with Sequential Method**##"
      ],
      "metadata": {
        "id": "1ngabp9HRymm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "# n_neurons = n_filter\n",
        "n_neurons = [10, 20, 30]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters = n_neurons[0], kernel_size =3, activation='relu'))\n",
        "model.add(Conv2D(filters = n_neurons[1], kernel_size =3, activation='relu'))\n",
        "model.add(Conv2D(filters = n_neurons[2], kernel_size =3, activation='relu'))\n",
        "\n",
        "x = tf.random.normal(shape=(32, 28, 28, 3))\n",
        "predictions = model(x)\n",
        "\n",
        "print(\"Input: {}\".format(x.shape))\n",
        "print(\"Output: {}\".format(predictions.shape))\n",
        "\n",
        "for layer in model.layers:\n",
        "  W, B = layer.get_weights()\n",
        "  print(W.shape, B.shape)\n",
        "  \n",
        "print('====')\n",
        "trainable_variables = model.trainable_variables\n",
        "for train_var in trainable_variables:\n",
        "  print(train_var.shape)"
      ],
      "metadata": {
        "id": "hJ3E8jzvRyz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f0e054a-6d1b-4ef2-f59c-d0d28b80955e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: (32, 28, 28, 3)\n",
            "Output: (32, 22, 22, 30)\n",
            "(3, 3, 3, 10) (10,)\n",
            "(3, 3, 10, 20) (20,)\n",
            "(3, 3, 20, 30) (30,)\n",
            "====\n",
            "(3, 3, 3, 10)\n",
            "(10,)\n",
            "(3, 3, 10, 20)\n",
            "(20,)\n",
            "(3, 3, 20, 30)\n",
            "(30,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**5-4-2: Models with Model Sub-classing**##"
      ],
      "metadata": {
        "id": "vxhsIpE7Ry5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "\n",
        "# n_neurons = n_filter\n",
        "n_neurons = [10, 20, 30]\n",
        "\n",
        "class TestModel(Model):\n",
        "    def __init__(self):\n",
        "        super(TestModel, self).__init__()\n",
        "        global n_neurons\n",
        "\n",
        "        self.conv_layers = []\n",
        "        for n_neuron in n_neurons:\n",
        "            self.conv_layers.append(Conv2D(filters=n_neuron, kernel_size=3, activation='relu'))\n",
        "\n",
        "    def call(self, x):\n",
        "          print(\"Input: \",x.shape)\n",
        "\n",
        "          print(\"\\n==== Conv layers ====\\n\")\n",
        "          for conv_layer in self.conv_layers:\n",
        "              x = conv_layer(x)\n",
        "              W, B = conv_layer.get_weights()\n",
        "              print(\"W/B: {}/{}\".format(W.shape, B.shape))\n",
        "              print(\"X: {}\".format(x.shape))\n",
        "          return x \n",
        "\n",
        "model = TestModel()\n",
        "x = tf.random.normal(shape=(32, 28, 28, 3))\n",
        "predictions = model(x)\n",
        "\n",
        "#============================================================================\n",
        "class TestModel(Model):\n",
        "    def __init__(self):\n",
        "        super(TestModel, self).__init__()\n",
        "        global n_neurons\n",
        "\n",
        "        self.conv1 = Conv2D(filters=n_neuron[0], kernel_size=3, activation='relu')\n",
        "        self.conv2 = Conv2D(filters=n_neuron[1], kernel_size=3, activation='relu')\n",
        "        self.conv3 = Conv2D(filters=n_neuron[2], kernel_size=3, activation='relu')\n",
        "\n",
        "    def call(self, x):\n",
        "          x = self.conv1(x)\n",
        "          x = self.conv2(x)\n",
        "          x = self.conv3(x)\n",
        "          return x "
      ],
      "metadata": {
        "id": "LLktOPh6RzD5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4224691-abc3-423e-fda4-dc776bcd160a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:  (32, 28, 28, 3)\n",
            "\n",
            "==== Conv layers ====\n",
            "\n",
            "W/B: (3, 3, 3, 10)/(10,)\n",
            "X: (32, 26, 26, 10)\n",
            "W/B: (3, 3, 10, 20)/(20,)\n",
            "X: (32, 24, 24, 20)\n",
            "W/B: (3, 3, 20, 30)/(30,)\n",
            "X: (32, 22, 22, 30)\n"
          ]
        }
      ]
    }
  ]
}